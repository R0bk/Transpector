## Supported Models
As Transpector uses `HookedModels` provided by [Transformer Lens](https://github.com/neelnanda-io/TransformerLens) the supported models will be the same, for ease of reference these models are supported as of June 2023:

- gpt2
- gpt2-medium
- gpt2-large
- gpt2-xl
- distilgpt2
- opt-125m
- opt-1.3b
- opt-2.7b
- opt-6.7b
- opt-13b
- opt-30b
- opt-66b
- gpt-neo-125M
- gpt-neo-1.3B
- gpt-neo-2.7B
- gpt-j-6B
- gpt-neox-20b
- alias-gpt2-small-x21
- battlestar-gpt2-small-x49
- caprica-gpt2-small-x81
- darkmatter-gpt2-small-x343
- expanse-gpt2-small-x777
- arwen-gpt2-medium-x21
- beren-gpt2-medium-x49
- celebrimbor-gpt2-medium-x81
- durin-gpt2-medium-x343
- eowyn-gpt2-medium-x777
- pythia-70m
- pythia-160m
- pythia-410m
- pythia-1b
- pythia-1.4b
- pythia-2.8b
- pythia-6.9b
- pythia-12b
- pythia-70m-deduped
- pythia-160m-deduped
- pythia-410m-deduped
- pythia-1b-deduped
- pythia-1.4b-deduped
- pythia-2.8b-deduped
- pythia-6.9b-deduped
- pythia-12b-deduped
- pythia-70m-v0
- pythia-160m-v0
- pythia-410m-v0
- pythia-1b-v0
- pythia-1.4b-v0
- pythia-2.8b-v0
- pythia-6.9b-v0
- pythia-12b-v0
- pythia-70m-deduped-v0
- pythia-160m-deduped-v0
- pythia-410m-deduped-v0
- pythia-1b-deduped-v0
- pythia-1.4b-deduped-v0
- pythia-2.8b-deduped-v0
- pythia-6.9b-deduped-v0
- pythia-12b-deduped-v0
- SoLU_1L_v9_old
- SoLU_2L_v10_old
- SoLU_4L_v11_old
- SoLU_6L_v13_old
- SoLU_8L_v21_old
- SoLU_10L_v22_old
- SoLU_12L_v23_old
- SoLU_1L512W_C4_Code
- SoLU_2L512W_C4_Code
- SoLU_3L512W_C4_Code
- SoLU_4L512W_C4_Code
- SoLU_6L768W_C4_Code
- SoLU_8L1024W_C4_Code
- SoLU_10L1280W_C4_Code
- SoLU_12L1536W_C4_Code
- GELU_1L512W_C4_Code
- GELU_2L512W_C4_Code
- GELU_3L512W_C4_Code
- GELU_4L512W_C4_Code
- Attn_Only_1L512W_C4_Code
- Attn_Only_2L512W_C4_Code
- Attn_Only_3L512W_C4_Code
- Attn_Only_4L512W_C4_Code
- Attn-Only-2L512W-Shortformer-6B-big-lr
- SoLU_1L512W_Wiki_Finetune
- SoLU_4L512W_Wiki_Finetune
- redwood_attn_2l
- llama-7b-hf
- llama-13b-hf
- llama-30b-hf
- llama-65b-hf

### Caveats 
- Currently shortformer models are only partially supported as the extra link is still displayed as if they were standard transformers.
- Some of these models are still yet to be tested, the largest of these require further work on performance optimisation before they can be used in Transpector confidently.